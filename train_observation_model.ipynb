{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tMs2ous6gal"
      },
      "source": [
        "Here is a notebook that you can upload to colab to train your model. \n",
        "\n",
        "### Instructions\n",
        "Before training you will need to upload:\n",
        "```\n",
        "hw1_train_dataset.zip\n",
        "hw1_test_dataset.zip\n",
        "observation_model.py\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TgU1cstMAuF6"
      },
      "outputs": [],
      "source": [
        "# You can change this supervision_mode between 'phi' and 'xy'. See the assinment pdf for more details.\n",
        "supervision_mode = 'phi'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPMuRRjTc9nr"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import math\n",
        "import zipfile\n",
        "import os\n",
        "from io import BytesIO\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import IPython.display\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import PIL\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Krj3ttnQYrEr"
      },
      "outputs": [],
      "source": [
        "# Upload observation_model.py from your assignment folder before running this\n",
        "# run this each time you want to reload the observation_model code\n",
        "import observation_model\n",
        "import importlib\n",
        "import observation_model\n",
        "importlib.reload(observation_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUEvZ6rfVLgO"
      },
      "outputs": [],
      "source": [
        "# minimized angle function from utils\n",
        "def minimized_angle(angle):\n",
        "    \"\"\"Normalize an angle to [-pi, pi].\"\"\"\n",
        "    while angle < -np.pi:\n",
        "        angle += 2 * np.pi\n",
        "    while angle >= np.pi:\n",
        "        angle -= 2 * np.pi\n",
        "    return angle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0B3hDPc0mqMH"
      },
      "outputs": [],
      "source": [
        "# function for displaying images\n",
        "def display_array(a, fmt='png'):\n",
        "    a = np.uint8(a)\n",
        "    f = BytesIO()\n",
        "    PIL.Image.fromarray(a).save(f, fmt)\n",
        "    IPython.display.display(IPython.display.Image(data=f.getvalue()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5lljflNmqMH"
      },
      "outputs": [],
      "source": [
        "# visualization functions\n",
        "def phi_to_i_x(phi):\n",
        "    c = np.cos(phi)\n",
        "    s = np.sin(phi)\n",
        "    if np.abs(c) > np.abs(s):\n",
        "        x = -s/c\n",
        "        if c > 0.:\n",
        "            i = 1\n",
        "        else:\n",
        "            i = 3\n",
        "    else:\n",
        "        x = c/s\n",
        "        if s > 0.:\n",
        "            i = 0\n",
        "        else:\n",
        "            i = 2\n",
        "    x = int(np.floor((x-0.0000001)*16)+16)\n",
        "    return i, x\n",
        "    \n",
        "def make_visualization(image, labels, phis):\n",
        "    quadrants = [np.full((16, 32, 3), 255, dtype=np.uint8) for _ in range(4)]\n",
        "    colors = [\n",
        "            [230,   0,   0],\n",
        "            [  0, 230,   0],\n",
        "            [  0, 0.0, 230],\n",
        "            [128, 128, 0.0],\n",
        "            [0.0, 128, 128],\n",
        "            [128, 0.0, 128],\n",
        "    ]\n",
        "    for la, color in zip(labels, colors):\n",
        "        i, x = phi_to_i_x(la)\n",
        "        quadrants[i][:8,x] = color\n",
        "    for th, color in zip(phis, colors):\n",
        "        i, x = phi_to_i_x(th)\n",
        "        quadrants[i][8:,x] = color\n",
        "    strip = np.concatenate(quadrants, axis=1)\n",
        "    strip = np.concatenate([strip[:,-16:], strip[:,:-16]], axis=1)\n",
        "    \n",
        "    return np.concatenate([image, strip], axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset and Dataloader:\n",
        "\n",
        "A custom Dataset class is implemented to fetch the data and labels. To do this we must implement three functions: __init__, __len__, and __getitem__. This has been done for you but check out this [link](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) to learn more about creating your own datasets. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLvLqM2Tzqzb"
      },
      "outputs": [],
      "source": [
        "class CarDataset(Dataset):\n",
        "    '''\n",
        "    Returns:\n",
        "        images as 32x128x3 numpy arrays\n",
        "        labels as 6 numpy arrays\n",
        "    '''\n",
        "    def __init__(self, path, subset=None):\n",
        "        self.zip = zipfile.ZipFile(path)\n",
        "        files = self.zip.namelist()\n",
        "        self.images = sorted([f for f in files if f.endswith('.png')])\n",
        "        self.labels = sorted([f for f in files if f.endswith('.npy')])\n",
        "        if subset is not None:\n",
        "            self.images = self.images[:subset]\n",
        "            self.labels = self.labels[:subset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        image = np.array(PIL.Image.open(self.zip.open(self.images[i])))\n",
        "        label = np.load(self.zip.open(self.labels[i]))\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcl6HDGq0cw6"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess the data into appropriate formats and split it into training, validation and testing sets.\n",
        "batch_size = 64\n",
        "train_dataset = CarDataset('hw1_train_dataset.zip')\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = CarDataset('hw1_test_dataset.zip')\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model and Optimizer:\n",
        "\n",
        "The model is being imported from the observation_model.py. In order to change your model architecture edit the observation_model.py. We have already implemented a basic neural network for you. \n",
        "\n",
        "We will be using the adam optimizer to update the weights of the model during training to minimize the loss. Click on the [link](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam) to learn more about the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ck1KlyaZ_UVt"
      },
      "outputs": [],
      "source": [
        "# build the model and optimizer\n",
        "if supervision_mode == 'phi':\n",
        "    output_channels = 6\n",
        "elif supervision_mode == 'xy':\n",
        "    output_channels = 12\n",
        "model = observation_model.ObservationModel(output_channels).cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jAbzzaU71CD",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "num_epochs = 20\n",
        "losses = []\n",
        "# Loop over the training data and for each iteration perform the following steps:\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    print('Epoch: %i'%epoch)\n",
        "    print('Training')\n",
        "    # This tells your model that you are training the model. This helps inform layers such as Dropout and BatchNorm,\n",
        "    # which are designed to behave differently during training and evaluation.\n",
        "    model.train()\n",
        "    iterate = tqdm(train_loader)\n",
        "    for x, y in iterate:\n",
        "        # Move to cuda, normalize the image between 0 and 1 and\n",
        "        # change the ordering to b,c,h,w\n",
        "        x = (x.float().cuda() / 255.).permute(0,3,1,2)\n",
        "        b = x.shape[0]\n",
        "        y = y.float().view(b,6).cuda()\n",
        "\n",
        "        # Pass the input through the model and get the predicted output.\n",
        "        x = model(x)\n",
        "\n",
        "        if supervision_mode == 'phi':\n",
        "            assert x.shape[1] == 6\n",
        "        elif supervision_mode == 'xy':\n",
        "            y = torch.cat([torch.cos(y), torch.sin(y)], dim=1)\n",
        "            assert x.shape[1] == 12\n",
        "        else:\n",
        "            raise ValueError('Unknown supervision_mode: %s'%supervision_mode)\n",
        "\n",
        "        # Define a loss function that measures the difference between the predicted and actual output of the network.\n",
        "        loss = F.mse_loss(x,y)\n",
        "\n",
        "        # Calculate the gradients of the loss with respect to the model parameters using backpropagation and \n",
        "        # Update the model parameters using the optimizer.\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Save the losses to further analysis\n",
        "        losses.append(float(loss))\n",
        "        recent_losses = losses[-100:]\n",
        "        running_loss = sum(recent_losses)/len(recent_losses)\n",
        "        iterate.set_description('Loss: %.04f'%running_loss)\n",
        "\n",
        "    # Plot the losses\n",
        "    plt.plot(np.arange(len(losses)), losses, label='loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    # Following is the testing loop used to evaluate the final performance of the model on the testing set after training is complete.\n",
        "    print('Evaluating')\n",
        "    all_errors = []\n",
        "    model.eval()\n",
        "    # the gradiants are only required for backprop and we do not need to calculate it during eval.\n",
        "    with torch.no_grad():\n",
        "        for i, (image, label) in enumerate(tqdm(test_loader)):\n",
        "            # Move to cuda, normalize the image between 0 and 1 and\n",
        "            # change the ordering to b,c,h,w\n",
        "            x = image.float().cuda() / 255.\n",
        "            x = x.permute(0,3,1,2)\n",
        "            b = x.shape[0]\n",
        "            y = label.float().view(b,6).cuda()\n",
        "\n",
        "            # Pass the input through the model and get the predicted output.\n",
        "            x = model(x)\n",
        "            if supervision_mode == 'phi':\n",
        "                phi = x\n",
        "            elif supervision_mode == 'xy':\n",
        "                phi = torch.atan2(x[:,6:], x[:,:6])\n",
        "            else:\n",
        "                raise ValueError('Unknown supervision_mode: %s'%supervision_mode)\n",
        "\n",
        "            # Calculate the error metric\n",
        "            error = (phi-y).view(-1).cpu().numpy()\n",
        "            error = [abs(minimized_angle(float(e))) for e in error]\n",
        "            all_errors.extend(error)\n",
        "            if i == 0:\n",
        "                for im, la, ph in zip(image[:10], label[:10], phi[:10]):\n",
        "                    la = la.detach().cpu().numpy()\n",
        "                    ph = ph.detach().cpu().numpy()\n",
        "                    vis = make_visualization(im, la, ph)\n",
        "                    display_array(vis)\n",
        "    \n",
        "    # Calculate the average error.\n",
        "    error_mean = np.mean(all_errors)\n",
        "    error_std = np.std(all_errors)\n",
        "    print('Error Mean: %f'%float(error_mean))\n",
        "    print('Error Std: %f'%float(error_std))\n",
        "    \n",
        "    # Save the final trained model so that it can be used for making predictions on new data.\n",
        "    print('Saving Checkpoint')\n",
        "    state_dict = model.state_dict()\n",
        "    torch.save(state_dict, 'checkpoint.pt')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
